{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQxGDH2F9WMy"
      },
      "source": [
        "Install PySpark if using Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iJOPfYP9Jma",
        "outputId": "42671cc5-67c8-49ac-e6bf-7b499119864c"
      },
      "outputs": [],
      "source": [
        "#!pip install pyspark\n",
        "# Use wget linux command to download the file and store it to the local folder\n",
        "# !wget https://raw.githubusercontent.com/trajanov/BigDataAnalytics/master/data/netflix-subscription.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2JFDUqd9fC-"
      },
      "source": [
        "### Initialize PySpark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "V2hUdZNK9J1r",
        "outputId": "2c20f0b3-c81f-428d-abdb-f5a4584141da"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext(\"local\")\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C227f_ChMoHC",
        "outputId": "a46d5f91-f536-4a83-9fa1-f6e303540ee4"
      },
      "outputs": [],
      "source": [
        "# Use wget linux command to download the file and store it to the local folder\n",
        "# !wget https://raw.githubusercontent.com/trajanov/BigDataAnalytics/master/data/netflix-subscription.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW_vHFjHTlZp"
      },
      "source": [
        "### Create a PySpark DataFrame from the netflix-subscription.csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "pyjko3EJ2Zvq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+---------+------------------+------------+----------+--------------------+-----------------------+----------------------+\n",
            "|Country_Code|  Country|Total_Library_Size|Num_TV_Shows|Num_Movies|Cost_Per_Month_Basic|Cost_Per_Month_Standard|Cost_Per_Month_Premium|\n",
            "+------------+---------+------------------+------------+----------+--------------------+-----------------------+----------------------+\n",
            "|          ar|Argentina|              4760|        3154|      1606|                3.74|                    6.3|                  9.26|\n",
            "|          au|Australia|              6114|        4050|      2064|                7.84|                  12.12|                 16.39|\n",
            "|          at|  Austria|              5640|        3779|      1861|                9.03|                  14.67|                 20.32|\n",
            "|          be|  Belgium|              4990|        3374|      1616|               10.16|                  15.24|                 20.32|\n",
            "|          bo|  Bolivia|              4991|        3155|      1836|                7.99|                  10.99|                 13.99|\n",
            "+------------+---------+------------------+------------+----------+--------------------+-----------------------+----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Create a DataFrame\n",
        "df = spark.read.csv(\"data\\\\netflix-subscription.csv\", header=True, inferSchema=True)\n",
        "# Show sample records\n",
        "df.show(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the feature vector and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[2274.0,1675.0,59...| 9.03|\n",
            "|[3048.0,1712.0,13...|12.88|\n",
            "|[3887.0,2449.0,14...| 8.36|\n",
            "|[4045.0,2638.0,14...| 9.03|\n",
            "|[4361.0,2973.0,13...| 10.9|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create features vector\n",
        "feature_columns = [\"Total_Library_Size\",\"Num_TV_Shows\",\"Num_Movies\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
        "df = df.withColumnRenamed(\"Cost_Per_Month_Basic\",\"label\")\n",
        "df = assembler.transform(df).select(\"features\",\"label\")\n",
        "\n",
        "# Train-Test split\n",
        "train, test = df.randomSplit(weights=[0.7,0.3], seed=200)\n",
        "train.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients: [-7.965004316307868e-06,0.0002585904963213735,-0.001742711925249158]\n",
            "Intercept: 10.859474972201737\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(maxIter=50)\n",
        "\n",
        "# Fit the model\n",
        "lrModel = lr.fit(train)\n",
        "\n",
        "# Print the coefficients and intercept for linear regression\n",
        "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
        "print(\"Intercept: %s\" % str(lrModel.intercept))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(9.03, 10.69193405548763),\n",
              " (9.03, 8.916280789046422),\n",
              " (1.97, 8.601900791149198),\n",
              " (7.99, 8.773585578709653),\n",
              " (7.99, 8.437455608233083)]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicrions = lrModel.transform(test)\n",
        "predRDD = predicrions.select(*[\"label\",\"prediction\"]).rdd.map(tuple)\n",
        "predRDD.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE 1.6545303554482729\n",
            "MSE 6.09946883815713\n"
          ]
        }
      ],
      "source": [
        "from pyspark.mllib.evaluation import RegressionMetrics\n",
        "metrics = RegressionMetrics(predRDD)\n",
        "print(\"MAE\", metrics.meanAbsoluteError)\n",
        "print(\"MSE\", metrics.meanSquaredError)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GeneralizedLinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients: [-7.965004316307868e-06,0.0002585904963213735,-0.001742711925249158]\n",
            "Intercept: 10.859474972201737\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "\n",
        "glr = GeneralizedLinearRegression(family=\"gaussian\", maxIter=50)\n",
        "\n",
        "# Fit the model\n",
        "model = glr.fit(train)\n",
        "\n",
        "# Print the coefficients and intercept for generalized linear regression model\n",
        "print(\"Coefficients: \" + str(model.coefficients))\n",
        "print(\"Intercept: \" + str(model.intercept))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(9.03, 10.69193405548763),\n",
              " (9.03, 8.916280789046422),\n",
              " (1.97, 8.601900791149198),\n",
              " (7.99, 8.773585578709653),\n",
              " (7.99, 8.437455608233083)]"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicrions = model.transform(test)\n",
        "predRDD = predicrions.select(*[\"label\",\"prediction\"]).rdd.map(tuple)\n",
        "predRDD.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE 1.6545303554482729\n",
            "MSE 6.09946883815713\n"
          ]
        }
      ],
      "source": [
        "from pyspark.mllib.evaluation import RegressionMetrics\n",
        "metrics = RegressionMetrics(predRDD)\n",
        "print(\"MAE\", metrics.meanAbsoluteError)\n",
        "print(\"MSE\", metrics.meanSquaredError)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q10: Improve the model\n",
        "Only simple improvement using a non-linear model that slightly improves the performance is implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "gbt = DecisionTreeRegressor(maxDepth=5,maxBins=5)\n",
        "#gbt = GBTRegressor(maxIter=4, maxDepth = 5, maxBins=5)\n",
        "model = gbt.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(9.03, 10.305714285714284),\n",
              " (9.03, 10.305714285714284),\n",
              " (1.97, 8.08),\n",
              " (7.99, 8.064285714285715),\n",
              " (7.99, 8.064285714285715)]"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicrions = model.transform(test)\n",
        "predRDD = predicrions.select(*[\"label\",\"prediction\"]).rdd.map(tuple)\n",
        "predRDD.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE 1.5173424036281176\n",
            "MSE 5.527559933484507\n"
          ]
        }
      ],
      "source": [
        "from pyspark.mllib.evaluation import RegressionMetrics\n",
        "metrics = RegressionMetrics(predRDD)\n",
        "print(\"MAE\", metrics.meanAbsoluteError)\n",
        "print(\"MSE\", metrics.meanSquaredError)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('spark')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "9db6cbf0fd79f8e79653fe7b0c50b956ca6e525ee712295da3c66f75e4fe96ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
